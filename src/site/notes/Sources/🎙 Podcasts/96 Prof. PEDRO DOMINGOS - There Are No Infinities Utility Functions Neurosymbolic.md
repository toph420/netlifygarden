---
{"dg-publish":true,"permalink":"/sources/podcasts/96-prof-pedro-domingos-there-are-no-infinities-utility-functions-neurosymbolic/"}
---

> [!multi-column]
>
>> [!metadata]- Meta
>> **up**:: [[Atlas/ðŸ“¥ Sources\|ðŸ“¥ Sources]]
>> **type**:: #ðŸ“¥/ðŸŽ™ 
>> **status**:: #ðŸ“¥/ðŸŸ¨ 
>> **tags**:: #on/podcasts
>> **topics**::  [[Cards/600 - Applied Sciences/Technology/AI/ðŸ¤– Artificial Intelligence\|ðŸ¤– Artificial Intelligence]], [[Cards/600 - Applied Sciences/Technology/AI/Large Language Models\|LLM]]
>
>> [!metadata]- Podcast Info
>> **Author**:: Machine Learning Street Talk (MLST)
>> **Title**:: "#96 Prof. PEDRO DOMINGOS - There Are No Infinities, Utility Functions, Neurosymbolic"
>> **URL**:: https://share.snipd.com/episode/f60709ba-8aaa-4428-ae64-3eab4870c9d8
>> **Reviewed Date**:: [[2023-01-15 \|2023-01-15 ]]
>> **Finished Year**:: [[2023\|2023]]

# #96 Prof. PEDRO DOMINGOS - There Are No Infinities, Utility Functions, Neurosymbolic

## Highlights
> ## Is There a Master Algorithm?
> Summary:
> In your book, I guess I want to sketch out different types of AI architecture. So you get universal lists, this kind of deep-mind idea that a very simple underlying algorithm could produce everything. And then you get hybrid focus on the other side of the spectrum. And then there's an integrated approach in the middle. Like, where would you kind of place yourself on that continuum? Well, let me put it this way. If somebody tells you that they know how we're going to get to intelligence, you should be suspicious right away.
> > [!transcript]- Transcript:
> > Speaker 2
> > So in your book, I guess I want to sketch out different types of AI architecture. So you know, you get universal lists, this kind of deep-mind idea that a very simple underlying algorithm could produce everything. And then you get hybrid focus on the other side of the spectrum. And then there's an integrated approach in the middle. Like, where would you kind of place yourself on that continuum?
> > Speaker 1
> > I would place myself very much in the frame of mind. Well, let me put it this way. I don't know. But which is nobody does. If somebody tells you that they know how we're going to get to intelligence, you should be suspicious right away. But what do I think is the most promising approach and the one that ideally would be the best one if we can pull it off? It's there being a single algorithm. So at that level, I very much sympathize with what is effectively the mind's agenda. Now, where I part with a lot of these people is that I don't think that the algorithm that we need is as simple as many of those people think it is. And I don't think it exists. It is probably the case that the algorithm that we really need at the end of the day doesn't even look that much like any of the things that we have now. So I think hopefully there is such an algorithm, but we're still far from it.
> > Speaker 2
> > Interesting. I mean, they would cite the example of evolution as being a very simple underlying algorithm, although Ken Stanley would say that people misunderstand evolution.
> > Speaker 1
> > So I agree with them at that level. In fact, in the master algorithm, I have a chapter where I go over the objections and the reasons to believe that there is a master algorithm.

> ## Is There Such a Thing?
> Summary:
> I think the context is, is there such a thing that will produce what we want? Well, yeah. In the book I mentioned, empirical evidence that there is a master algorithm. An exhibit one is evolution. Another example is your brain. But then there's another one, which is even more fundamental, which is the laws of physics. The laws of physics are the master algorithm.
> > [!transcript]-  Transcript:
> > Speaker 2
> > But in a sense, we know there is such a thing. Look at cellular automata. Look at what we've already done with deep learning. I think the context is, is there such a thing that will produce what we want?
> > Speaker 1
> > Well, yeah. To take your example, or the mind's example of evolution. In the book I mentioned, empirical evidence that there is a master algorithm. An exhibit one is evolution. If you think of evolution as an algorithm, which, by the way, is a very old idea, I think it was George Boole that said, God does not create animals and plants. He creates the algorithm by which animals and plants come about. He didn't use the word algorithm, but that's essential to what he said. This, I think, is right on. Another example is your brain. If the algorithm doesn't have to be something as simple as backprop and you're a materialist, like most of the scientists start, your brain, if the master algorithm is an algorithm that can learn anything you do, then your brain is that algorithm. But then there's another one, which is even more fundamental, but I think from the point of view of this debate is very illuminating, which is the laws of physics. Why stop at evolution? The laws of physics are the master algorithm. Evolution is very complicated. In fact, what I think about evolution in the eye currently is that evolution in reality is much more complex than we give it credits for, which is why a lot of our current genetic algorithms don't work that well.

> ## The Wisdom of Crowds
> Summary:
> There's a question of whether it's beyond the cognitive ability of a single human. And then there's the question of if it is beyond the Cognitive horizon of an entire society of humans. But we don't mean, how do we know that the crowd understands what we know was well? The beauty of this, in some sense, is that we never, what is the crowd really understanding right.
> > [!transcript]- Transcript:
> > Speaker 1
> > Yes. There's a question of whether it's beyond the cognitive ability of a single human. Yeah. And then there's the question of whether it's beyond the cognitive ability of an entire society of humans. And obviously, there'll be things that are beyond the cognitive ability of a single human, but not beyond the cognitive ability of a society. Also, these days, we have computers. So our cognitive power is augmented by our machines. So we can understand things or bring things to the point where we understand them to the degree today that we couldn't 100 years ago.
> > Speaker 2
> > Right. Now, that is a fascinating point. So it's beyond our cognitive horizon individually, but it might not be beyond the cognitive horizon of loads and loads of humans on the Internet, you know, the wisdom of crowds.
> > Speaker 1
> > But we don't mean, how do we know that the crowd understands what we know was well, that's the, the, in some sense, the beauty of this, right, is that we never, what is the crowd really understanding right. And again, once the crowd is augmented by machines like machine learning algorithms, right, we can ask, what do we as a society equipped with all of our, you know, large language models and so on and so forth. What do we really understand right now at some level, you can't answer that question individually because you are just an individual, but right there's a couple of very important things that we shouldn't forget one is that you could one thing you can do and that I do do say like, do I now actually even just individually understand things better than I did before when it was just me looking at it. And the answer to that is almost invariably yes right so so there is a big game to be here there.

> ## The LLM Is Still the LLM
> Summary:
> We tend to have this notion that creativity is something magical. It's a very human enterprise and it can very well be automated. We need to, we can critique how creative it is or not. But we need to give it credit for what it does.
> > [!transcript]- Transcript:
> > Speaker 1
> > I would disagree with that. I think you are. I mean, your position is very reasonable and actually, I would say probably the most common but I think when you do that, you are giving us too much credit and the large language models too little. We tend to have this notion that creativity is something magical. But I remember for many years so with parentheses, in the previous life I was a musician. So, you know, I, in some sense, know about a lot of my job was composing songs. Right. And I was always at the same time I was already studying AI and I couldn't help but connected to right then and think about like, what would an AI look that was able to compose music. Right. And, and talking to lay people who are not musicians, they think that composing songs is some kind of magic thing that comes from, you know, whatever the great beyond and it's not. It's a very human enterprise and it can very well be automated. It's actually now, you know, people used to say to people like, people always say like, Oh, creativity will be the last thing that we automate because we humans can do it and there's no machine and be like, no, it's going to be the opposite. You'll automate creativity long before many other things and we're there now. Right. In just the last. So, I think when you let me put it this way. Your prompt to the LLM, let's say, is like the grain of sand to the oyster. Right. You should not give yourself credit for having made the pearl because you put the grain of sand in there.
> > Speaker 2
> > Right. That's a brilliant analogy. Right.
> > Speaker 1
> > So it is still the LLM. We need to, we can critique how creative it is or not. And there's a lot to be said there and a lot of progress to be made. But we need to give it credit for what it does. Right. It is a well or not so well. Right. Maybe it's more of an illusion that we're giving you credit for and whatnot.

> There's Nothing Magical About Creativity
> Summary:
> Creativity really is, to a large extent, cutting and pasting stuff. And I'm not just saying this in the abstract, like long before the modern era. A composer at UC Santa Cruz created programs that exactly they would write. It was list code that what it did was basically have rules about how music should be. Then it takes snippets and combines them.
> > [!transcript]- Transcript:
> > Speaker 1
> > Well, but we by that standard, we humans also only do what we're told to do. We do what we're told to do by our genes, our genes do what they told to do by evolution, which does what it's told to do by the laws of physics. Right. Right. And now, again, this gets back to this notion that there's nothing magical about creativity. Creativity really is, to a large extent, cutting and pasting stuff and satisfying consistency constraints between them. And I'm not just saying this in the abstract, like long before the modern era. There's this guy called David Kope, you know, a composer and professor of music at UC Santa Cruz, who created these programs that exactly they would write. They can write this was pre machine learning. Right. It was list code that what it did was basically have rules about how music should be. And then it takes snippets and combines them. Right. You could say it's just parrotting those bits, but the truth is at the end of the day. And you can choose, you say, like, give me something in the style of Mozart, and it creates something by that looks indistinguishable from what Mozart did. But all it's doing is this kind of recombination of pieces. So we humans, we have too much respect for appreciation for our own intelligence. That's also what we're doing.
> > Speaker 2
> > Yeah, I think I agree with you. First of all, intelligence is a receding horizon and there's the Macorda effect. And I agree with all of that.

> The Paperclip Experiment Is Simplistic
> Summary:
> You have an enormous amount of AI at the service of maximizing engagement. It's a very, I understand why companies do it and partly they have the right to. We're never going to have the final to leave function is something that the AIs have to be continually you know, Stuart Russell said this: They should spend half their time figuring out what the function is. And then the other half maximizing it.
> > [!transcript]- Transcript
> > Speaker 1
> > Right. You have an enormous amount of AI at the service of maximizing engagement. It's a very, I understand why companies do it and partly they have the right to. We can get into that. But the point is the consequence, it's ignoring too many things. Right. So one line of defense against is like, you have to enrich you to leave function until it's like a bed. And then is it this is an open ended problem. Right. We're never, we're never going to have the final to leave function is something that the AIs have to be continually you know, AIs, I think Stuart Russell said this and I agree, like, they should spend half their time figuring out what the function is. And then the other half maximizing it. Whereas today it's like, I wrote down my function in one line. And now I spend this enormous amount of power maximizing it. So that's one line. The other line or like one other line is you have to put constraints on the machine. Hard constraints. You can't win the pursuit of this function. You can think of it as like, you know, terms with infinite weight in the function, you can't go outside this. And then the other one is the single biggest reason I sort of like this paperclip experiment is silly is that, you know, along with that paperclip factor in the world, they're going to be a million other AIs, you know, each of which is doing the same thing. So none of them is ever going to acquire the power to cause that damage unless it's doing something very different from just trying to make paperclip. So at some level, that example is extremely unrealistic and leads us down the wrong track.

> Nudging: The Art of Emergence
> Key takeaways:
> (* Everything is emergent., * The utility function should emerge and evolve., * Morphogenetic engineering is a form of emergence where we nudge things to create a hybrid between something which is emerging and something which we can control.)
> > [!transcript]- Transcript
> > Transcript:
> > Speaker 1
> > But it's still relatively glacial.
> > Speaker 2
> > And I take your point that there's a kind of divergence between the world we live in and the programming that we've got. But then, okay, let's imagine that we create a new population. And I guess what I'm saying is that you think that the utility function should emerge and evolve. But I would argue for some kind of morphogenetic engineering where it's a kind of hybrid between something which is emerging, but something which we can nudge.
> > Speaker 1
> > Oh, I mean, I'm glad you brought that up. Nudging is a form of emergence. You are self-emergent and the things that you do are emergent as well. Everything is emergent, right? Utilities are emergent. Maybe the laws of physics aren't emergent. Some people will say even those are, right? Like, you know, we live in a universe with this constants because blah, blah, blah. Right. So, but to first approximation, every single thing that we've been talking about is emergent. We make a distinction between emergent and designed because that is anthropomorphic, right? Is this things that we do are not emergent? Actually, no. When you nudge something that is an emergent behavior, right? We are emergent as well, right? So everything that is human, you know, so he's a very good way, I think, to think about a lot of things which I first saw, you know, in Richard Dawkins, which is, although he really didn't go into this. And I wish he had like this notion of the extended phenotype, right? Technology is our extended phenotype.

---
up:: [[Atlas/ðŸ“¥ Sources\|ðŸ“¥ Sources]]
